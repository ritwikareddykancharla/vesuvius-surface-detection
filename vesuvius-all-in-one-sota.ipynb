{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸŒ‹ Vesuvius Challenge: SOTA Multi-Cube Pipeline (0.65+)\n",
                "\n",
                "### ðŸš¨ VERSION 3.0 - UNIVERSAL FIX\n",
                "> [!IMPORTANT]\n",
                "> **If you still see the error**: It means your browser/Kaggle is caching the old code. \n",
                "> **PLEASE**: Press `Ctrl + F5` to force-refresh this page, then **Kernel -> Restart & Run All**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "!pip install -q monai tifffile\n",
                "\n",
                "import os\n",
                "import glob\n",
                "import random\n",
                "import zipfile\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torch.cuda.amp import GradScaler, autocast\n",
                "from monai.networks.nets import SwinUNETR\n",
                "from tqdm.auto import tqdm\n",
                "import tifffile as tiff\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "print(f\"DEBUG: Code Version 3.0 Loaded (Positional Args Mode)\")\n",
                "\n",
                "# --- CONFIGURATION ---\n",
                "class CFG:\n",
                "    input_dir = '/kaggle/input/vesuvius-challenge-surface-detection'\n",
                "    test_dir = os.path.join(input_dir, 'test_images')\n",
                "    train_images = os.path.join(input_dir, 'train_images')\n",
                "    train_labels = os.path.join(input_dir, 'train_labels')\n",
                "    \n",
                "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "    patch_size = (128, 128, 128)\n",
                "    stride = 64\n",
                "    batch_size = 1 \n",
                "    lr = 2e-4\n",
                "    epochs = 15\n",
                "    \n",
                "    use_distance_map = True\n",
                "    tta = True\n",
                "    best_weights = \"best_sota_model.pth\"\n",
                "\n",
                "def seed_everything(seed=42):\n",
                "    random.seed(seed)\n",
                "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    torch.cuda.manual_seed(seed)\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "\n",
                "seed_everything()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Utilities"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def detect_umbilicus(volume):\n",
                "    coords = np.argwhere(volume > (0.2 if volume.dtype == np.float32 else 0))\n",
                "    if len(coords) == 0: return tuple(s // 2 for s in volume.shape)\n",
                "    return tuple(np.mean(coords, axis=0).astype(int))\n",
                "\n",
                "def get_radial_dist_map(shape, center):\n",
                "    z, y, x = np.ogrid[:shape[0], :shape[1], :shape[2]]\n",
                "    dist = np.sqrt((z-center[0])**2 + (y-center[1])**2 + (x-center[2])**2)\n",
                "    return (dist / (np.max(dist) + 1e-8)).astype(np.float32)\n",
                "\n",
                "def compute_dice(pred, target):\n",
                "    pred = (torch.sigmoid(pred) > 0.5).float()\n",
                "    intersection = (pred * target).sum()\n",
                "    return (2. * intersection + 1e-6) / (pred.sum() + target.sum() + 1e-6)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "class VesuviusCubeDataset(Dataset):\n",
                "    def __init__(self, img_paths, label_dir, is_train=True):\n",
                "        self.img_paths = img_paths\n",
                "        self.label_dir = label_dir\n",
                "        self.is_train = is_train\n",
                "        \n",
                "    def __len__(self): return len(self.img_paths)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        path = self.img_paths[idx]\n",
                "        vid = os.path.basename(path).split('.')[0]\n",
                "        vol = (tiff.imread(path) / 255.0).astype(np.float32)\n",
                "        center = detect_umbilicus(vol)\n",
                "        dist = get_radial_dist_map(vol.shape, center)\n",
                "        img_patch = np.stack([vol, dist], axis=0)\n",
                "        \n",
                "        if self.is_train:\n",
                "            lab_path = os.path.join(self.label_dir, f\"{vid}.tif\")\n",
                "            lab = (tiff.imread(lab_path) > 0).astype(np.float32)\n",
                "            d, h, w = vol.shape\n",
                "            z, y, x = [random.randint(0, s - 128) for s in [d, h, w]]\n",
                "            return torch.from_numpy(img_patch[:, z:z+128, y:y+128, x:x+128]), \\\n",
                "                   torch.from_numpy(lab[z:z+128, y:y+128, x:x+128][None, :])\n",
                "        \n",
                "        return torch.from_numpy(img_patch), vid"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Loss & Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "def medial_surface_recall(pred, target):\n",
                "    def get_2d_skel(x, kernel=(1, 3, 3)):\n",
                "        x1 = -F.max_pool3d(-F.max_pool3d(x, kernel, 1, (0, 1, 1)), kernel, 1, (0, 1, 1))\n",
                "        return F.relu(x - x1)\n",
                "    skel_z = get_2d_skel(pred, (1, 3, 3))\n",
                "    skel_y = get_2d_skel(pred.transpose(2, 3), (1, 3, 3)).transpose(2, 3)\n",
                "    skel_x = get_2d_skel(pred.transpose(2, 4), (1, 3, 3)).transpose(2, 4)\n",
                "    combined_skel = (skel_z + skel_y + skel_x) / 3.0\n",
                "    recall = (torch.sum(combined_skel * target) + 1e-6) / (torch.sum(combined_skel) + 1e-6)\n",
                "    return 1.0 - recall\n",
                "\n",
                "class VesuviusSotaLoss(nn.Module):\n",
                "    def __init__(self, w_skel=0.5):\n",
                "        super().__init__()\n",
                "        self.bce, self.w_skel = nn.BCEWithLogitsLoss(), w_skel\n",
                "    def forward(self, pred, target):\n",
                "        bce = self.bce(pred, target)\n",
                "        p = torch.sigmoid(pred)\n",
                "        srec = medial_surface_recall(p, target)\n",
                "        return (1.0 - self.w_skel) * bce + self.w_skel * srec\n",
                "\n",
                "def train():\n",
                "    print(\"\\n--- [DEBUG] VERSION 3.0: UNIVERSAL MODE ---\")\n",
                "    all_img_paths = glob.glob(os.path.join(CFG.train_images, \"*.tif\"))\n",
                "    train_paths, val_paths = train_test_split(all_img_paths, test_size=0.2, random_state=42)\n",
                "    \n",
                "    train_loader = DataLoader(VesuviusCubeDataset(train_paths, CFG.train_labels), batch_size=CFG.batch_size, shuffle=True)\n",
                "    val_loader = DataLoader(VesuviusCubeDataset(val_paths, CFG.train_labels), batch_size=CFG.batch_size, shuffle=False)\n",
                "    \n",
                "    # UNIVERSAL INITIALIZATION (POSITIONAL ONLY)\n",
                "    # Arguments: img_size, in_channels, out_channels, feature_size\n",
                "    model = SwinUNETR(CFG.patch_size, 2, 1, 48, use_checkpoint=True).to(CFG.device)\n",
                "    \n",
                "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr)\n",
                "    criterion, scaler = VesuviusSotaLoss(), GradScaler()\n",
                "    \n",
                "    best_dice = 0\n",
                "    for epoch in range(CFG.epochs):\n",
                "        model.train()\n",
                "        for img, lab in tqdm(train_loader, desc=f\"Epoch {epoch+1} [TRAIN]\"):\n",
                "            img, lab = img.to(CFG.device), lab.to(CFG.device)\n",
                "            optimizer.zero_grad()\n",
                "            with autocast(): loss = criterion(model(img), lab)\n",
                "            scaler.scale(loss).backward()\n",
                "            scaler.step(optimizer)\n",
                "            scaler.update()\n",
                "        \n",
                "        model.eval()\n",
                "        val_dice = 0\n",
                "        with torch.no_grad():\n",
                "            for img, lab in tqdm(val_loader, desc=f\"Epoch {epoch+1} [VAL]\"):\n",
                "                img, lab = img.to(CFG.device), lab.to(CFG.device)\n",
                "                val_dice += compute_dice(model(img), lab).item()\n",
                "        \n",
                "        avg_val_dice = val_dice / len(val_loader)\n",
                "        print(f\"Epoch {epoch+1} | Val Dice={avg_val_dice:.4f}\")\n",
                "        \n",
                "        if avg_val_dice > best_dice:\n",
                "            best_dice = avg_val_dice\n",
                "            torch.save(model.state_dict(), CFG.best_weights)\n",
                "    return CFG.best_weights\n",
                "\n",
                "def submit(weights):\n",
                "    model = SwinUNETR(CFG.patch_size, 2, 1, 48, use_checkpoint=True).to(CFG.device)\n",
                "    model.load_state_dict(torch.load(weights))\n",
                "    model.eval()\n",
                "    \n",
                "    test_paths = glob.glob(os.path.join(CFG.test_dir, \"*.tif\"))\n",
                "    with zipfile.ZipFile('submission.zip', 'w') as out_zip:\n",
                "        for path in test_paths:\n",
                "            vid, vol = os.path.basename(path).split('.')[0], (tiff.imread(path)/255.0).astype(np.float32)\n",
                "            dist = get_radial_dist_map(vol.shape, detect_umbilicus(vol))\n",
                "            full_pred, counts = np.zeros_like(vol), np.zeros_like(vol)\n",
                "            pd = CFG.patch_size[0]\n",
                "            for z in tqdm(range(0, vol.shape[0]-pd+1, CFG.stride), desc=f\"Cube {vid}\"):\n",
                "                for y in range(0, vol.shape[1]-pd+1, CFG.stride):\n",
                "                    for x in range(0, vol.shape[2]-pd+1, CFG.stride):\n",
                "                        patch = torch.from_numpy(np.stack([vol[z:z+pd, y:y+pd, x:x+pd], dist[z:z+pd, y:y+pd, x:x+pd]]))[None,:].to(CFG.device)\n",
                "                        with torch.no_grad(): full_pred[z:z+pd, y:y+pd, x:x+pd] += torch.sigmoid(model(patch)).squeeze().cpu().numpy()\n",
                "                        counts[z:z+pd, y:y+pd, x:x+pd] += 1.0\n",
                "            mask = (full_pred/(counts+1e-8) > 0.51).astype(np.uint8)\n",
                "            tiff.imwrite(f\"{vid}.tif\", mask, compression='lzw')\n",
                "            out_zip.write(f\"{vid}.tif\")\n",
                "            os.remove(f\"{vid}.tif\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": [
                "if __name__ == \"__main__\":\n",
                "    best_model_path = train()\n",
                "    submit(best_model_path)\n",
                "    print(\"\\n--- SUCCESS: SUBMISSION.ZIP CREATED ---\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}